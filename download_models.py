#!/usr/bin/env python3
"""
æ¨¡å‹ä¸‹è½½è„šæœ¬
æå‰ä¸‹è½½ pyannote-audio æ¨¡å‹ï¼Œé¿å…é¦–æ¬¡è¿è¡Œæ—¶ç­‰å¾…
"""
import os
import sys
from pathlib import Path

def check_token():
    """æ£€æŸ¥ Hugging Face Token"""
    token = os.getenv("HUGGINGFACE_TOKEN")
    
    if not token:
        print("âŒ é”™è¯¯: æœªè®¾ç½® HUGGINGFACE_TOKEN ç¯å¢ƒå˜é‡")
        print("\nè¯·æŒ‰ä»¥ä¸‹æ­¥éª¤æ“ä½œ:")
        print("1. è®¿é—® https://huggingface.co/settings/tokens")
        print("2. åˆ›å»ºæ–°çš„ token (Read æƒé™)")
        print("3. æ¥å—æ¨¡å‹ä½¿ç”¨æ¡æ¬¾:")
        print("   - https://huggingface.co/pyannote/speaker-diarization-3.1")
        print("   - https://huggingface.co/pyannote/segmentation-3.0")
        print("\n4. è®¾ç½®ç¯å¢ƒå˜é‡:")
        print("   export HUGGINGFACE_TOKEN=your_token_here")
        print("\næˆ–è€…åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½®")
        return False
    
    print(f"âœ“ æ£€æµ‹åˆ° HUGGINGFACE_TOKEN: {token[:10]}...{token[-4:]}")
    return True


def check_huggingface_cli():
    """æ£€æŸ¥ huggingface-cli æ˜¯å¦å®‰è£…"""
    import subprocess
    try:
        result = subprocess.run(
            ["huggingface-cli", "--version"],
            capture_output=True,
            text=True,
            timeout=5
        )
        if result.returncode == 0:
            return True
    except (FileNotFoundError, subprocess.TimeoutExpired):
        pass
    return False


def download_pyannote_models():
    """ä½¿ç”¨ huggingface-cli ä¸‹è½½ pyannote æ¨¡å‹"""
    print("\n" + "="*60)
    print("å¼€å§‹ä¸‹è½½ pyannote-audio æ¨¡å‹")
    print("="*60)
    
    # æ£€æŸ¥ huggingface-cli
    if not check_huggingface_cli():
        print("\nâŒ æœªæ‰¾åˆ° huggingface-cli")
        print("è¯·å…ˆå®‰è£…:")
        print("   pip install -U huggingface_hub[cli]")
        return False
    
    import subprocess
    
    # å…ˆç™»å½•
    token = os.getenv("HUGGINGFACE_TOKEN")
    print("\nğŸ” ä½¿ç”¨ Token ç™»å½• Hugging Face...")
    try:
        result = subprocess.run(
            ["huggingface-cli", "login", "--token", token],
            capture_output=True,
            text=True,
            timeout=10
        )
        if result.returncode == 0:
            print("âœ“ ç™»å½•æˆåŠŸ")
        else:
            print(f"âš ï¸  ç™»å½•è­¦å‘Š: {result.stderr}")
    except Exception as e:
        print(f"âš ï¸  ç™»å½•å¤±è´¥: {str(e)}")
        print("ç»§ç»­å°è¯•ä¸‹è½½...")
    
    # æ¨¡å‹åˆ—è¡¨
    models = [
        "pyannote/speaker-diarization-3.1",
        "pyannote/segmentation-3.0",
    ]
    
    success = True
    for model_name in models:
        print(f"\nğŸ“¦ ä¸‹è½½æ¨¡å‹: {model_name}")
        print("   è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…...")
        
        try:
            # ä½¿ç”¨ huggingface-cli ä¸‹è½½
            result = subprocess.run(
                ["huggingface-cli", "download", model_name],
                capture_output=False,  # æ˜¾ç¤ºä¸‹è½½è¿›åº¦
                text=True,
                timeout=600  # 10åˆ†é’Ÿè¶…æ—¶
            )
            
            if result.returncode == 0:
                print(f"   âœ“ {model_name} ä¸‹è½½å®Œæˆ")
            else:
                print(f"   âœ— {model_name} ä¸‹è½½å¤±è´¥")
                success = False
                
        except subprocess.TimeoutExpired:
            print(f"   âœ— {model_name} ä¸‹è½½è¶…æ—¶")
            success = False
        except Exception as e:
            print(f"   âœ— {model_name} ä¸‹è½½å¤±è´¥: {str(e)}")
            success = False
    
    if success:
        print("\n" + "="*60)
        print("âœ… æ‰€æœ‰ pyannote æ¨¡å‹ä¸‹è½½å®Œæˆï¼")
        print("="*60)
    else:
        print("\n" + "="*60)
        print("âš ï¸  éƒ¨åˆ†æ¨¡å‹ä¸‹è½½å¤±è´¥")
        print("="*60)
    
    return success


def check_glm_asr_model():
    """æ£€æŸ¥ GLM-ASR æ¨¡å‹"""
    print("\n" + "="*60)
    print("æ£€æŸ¥ GLM-ASR æ¨¡å‹")
    print("="*60)
    
    required_files = [
        "config.json",
        "generation_config.json",
        "tokenizer_config.json",
    ]
    
    missing = []
    for filename in required_files:
        if Path(filename).exists():
            print(f"âœ“ {filename}")
        else:
            print(f"âœ— {filename} (ç¼ºå¤±)")
            missing.append(filename)
    
    if missing:
        print("\nâš ï¸  GLM-ASR æ¨¡å‹æ–‡ä»¶ä¸å®Œæ•´")
        print("\nè¯·ä¸‹è½½æ¨¡å‹:")
        print("   æ–¹å¼1: Git LFS")
        print("   git lfs install")
        print("   git clone https://huggingface.co/zai-org/GLM-ASR-Nano-2512")
        print("\n   æ–¹å¼2: ä½¿ç”¨ huggingface_hub")
        print("   pip install huggingface_hub")
        print("   python -c \"from huggingface_hub import snapshot_download; snapshot_download('zai-org/GLM-ASR-Nano-2512', local_dir='.')\"")
        return False
    else:
        print("\nâœ… GLM-ASR æ¨¡å‹æ–‡ä»¶å®Œæ•´")
        return True


def test_imports():
    """æµ‹è¯•å…³é”®å¯¼å…¥"""
    print("\n" + "="*60)
    print("æµ‹è¯•ä¾èµ–åŒ…")
    print("="*60)
    
    packages = {
        "torch": "PyTorch",
        "torchaudio": "TorchAudio",
        "transformers": "Transformers",
        "pyannote.audio": "Pyannote Audio",
        "fastapi": "FastAPI",
        "uvicorn": "Uvicorn",
    }
    
    all_ok = True
    for package, name in packages.items():
        try:
            __import__(package)
            print(f"âœ“ {name}")
        except ImportError:
            print(f"âœ— {name} (æœªå®‰è£…)")
            all_ok = False
    
    if not all_ok:
        print("\nè¯·å®‰è£…ç¼ºå¤±çš„åŒ…:")
        print("   pip install -r requirements.txt")
        return False
    
    print("\nâœ… æ‰€æœ‰ä¾èµ–åŒ…å·²å®‰è£…")
    return True


def show_cache_info():
    """æ˜¾ç¤ºç¼“å­˜ä¿¡æ¯"""
    print("\n" + "="*60)
    print("ç¼“å­˜ä½ç½®")
    print("="*60)
    
    # Hugging Face ç¼“å­˜
    hf_cache = os.getenv("HF_HOME", os.path.expanduser("~/.cache/huggingface"))
    print(f"ğŸ“ Hugging Face ç¼“å­˜: {hf_cache}")
    
    # Transformers ç¼“å­˜
    transformers_cache = os.getenv("TRANSFORMERS_CACHE", os.path.expanduser("~/.cache/huggingface/transformers"))
    print(f"ğŸ“ Transformers ç¼“å­˜: {transformers_cache}")
    
    # PyTorch ç¼“å­˜
    torch_cache = os.getenv("TORCH_HOME", os.path.expanduser("~/.cache/torch"))
    print(f"ğŸ“ PyTorch ç¼“å­˜: {torch_cache}")
    
    print("\nğŸ’¡ æç¤º: å¦‚éœ€æ¸…ç†ç¼“å­˜ï¼Œå¯ä»¥åˆ é™¤ä¸Šè¿°ç›®å½•")


def main():
    """ä¸»å‡½æ•°"""
    print("="*60)
    print("GLM-ASR æœåŠ¡ - æ¨¡å‹ä¸‹è½½å·¥å…·")
    print("="*60)
    
    # åŠ è½½ .env æ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    try:
        from dotenv import load_dotenv
        if Path(".env").exists():
            load_dotenv()
            print("âœ“ å·²åŠ è½½ .env æ–‡ä»¶")
    except ImportError:
        pass
    
    # æ­¥éª¤1: æ£€æŸ¥ Token
    if not check_token():
        return 1
    
    # æ­¥éª¤2: æµ‹è¯•ä¾èµ–
    if not test_imports():
        return 1
    
    # æ­¥éª¤3: æ£€æŸ¥ GLM-ASR æ¨¡å‹
    check_glm_asr_model()
    
    # æ­¥éª¤4: ä¸‹è½½ pyannote æ¨¡å‹
    print("\næ˜¯å¦ä¸‹è½½ pyannote æ¨¡å‹? (è¿™éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´)")
    response = input("ç»§ç»­? [Y/n]: ").strip().lower()
    
    if response in ['', 'y', 'yes']:
        if not download_pyannote_models():
            return 1
    else:
        print("è·³è¿‡æ¨¡å‹ä¸‹è½½")
    
    # æ­¥éª¤5: æ˜¾ç¤ºç¼“å­˜ä¿¡æ¯
    show_cache_info()
    
    print("\n" + "="*60)
    print("âœ¨ è®¾ç½®å®Œæˆï¼")
    print("="*60)
    print("\nç°åœ¨å¯ä»¥å¯åŠ¨æœåŠ¡:")
    print("   python service.py")
    print("   # æˆ–")
    print("   ./start_service.sh")
    
    return 0


if __name__ == "__main__":
    sys.exit(main())
